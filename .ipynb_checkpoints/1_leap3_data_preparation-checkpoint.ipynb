{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTI and TBSS feature extraction for LEAP diffusion data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 156 subjects in total\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import subprocess\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import xmltodict\n",
    "import io\n",
    "\n",
    "#CPU command\n",
    "cluster_log_dir = '/home/preclineu/ramcir/Desktop/Clinical/logs/'\n",
    "cmd_qsub_base = ['/home/preclineu/ramcir/DCCN/Scripts/SubmitToCluster.py',\n",
    "                 '-length', '02:00:00',\n",
    "                 '-memory', '20GB',\n",
    "                 '-logfiledir', cluster_log_dir]\n",
    "\n",
    "#define data directory\n",
    "rootdir = '/project_cephfs/3022035.06/LEAP_wave3/'\n",
    "\n",
    "#get a list of subjects to process\n",
    "sub_dirs = [d for d in glob.glob(os.path.join(rootdir, '[0-9]*'))] \n",
    "sub_ids = [os.path.basename(d) for d in sub_dirs]\n",
    "print('Found', len(sub_dirs), 'subjects in total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 subjects who are ready for DTI\n",
      "Found 1 subjects who are ready for TBSS\n",
      "Found 155 subjects who already have DTIfit\n",
      "Found 155 subjects who already have TBSS\n"
     ]
    }
   ],
   "source": [
    "#Created empty lists of subs\n",
    "sub_dtifit_ready = []\n",
    "sub_dtifit_complete = []\n",
    "sub_tbss_ready = []\n",
    "sub_tbss_complete = []\n",
    "\n",
    "for s in sub_dirs[0:]:\n",
    "    #Define directories needed\n",
    "    subid = os.path.splitext(os.path.basename(s))[0] #get sub ID from path\n",
    "    diffdir = os.path.join(s, 'DWI', 'preprocessing') #directory where Diffsuion folders are stored\n",
    "    tbssdir = os.path.join(diffdir, 'tbss') #TBSS directory\n",
    "    dtidir = os.path.join(diffdir,'dti') #DTI directory\n",
    "    fa_path = os.path.join(dtidir, str(''.join([subid,'_dti_FA.nii.gz']))) #path to the FA image (the output of DTIfit)\n",
    "    skel_path = os.path.join(tbssdir,'stats','all_FA.nii.gz') #path to the FA_skeletonized image (the output of TBSS)\n",
    "    \n",
    "\n",
    "    #Check if DTIfit is complete\n",
    "    if os.path.exists(fa_path) == False:  \n",
    "        sub_dtifit_ready.append(s)\n",
    "    else: \n",
    "        sub_dtifit_complete.append(s)\n",
    "        \n",
    "    #Check if TBSS is complete\n",
    "    if os.path.exists(skel_path) == False:  \n",
    "        sub_tbss_ready.append(s)\n",
    "    else: \n",
    "        sub_tbss_complete.append(s)\n",
    "\n",
    "print('Found', len(sub_dtifit_ready), 'subjects who are ready for DTI')\n",
    "print('Found', len(sub_tbss_ready), 'subjects who are ready for TBSS')\n",
    "print('Found', len(sub_dtifit_complete), 'subjects who already have DTIfit')\n",
    "print('Found', len(sub_tbss_complete), 'subjects who already have TBSS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run DTIfit - to extract the DTI measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for s in sub_dtifit_ready[0:]:\n",
    "    # Extract subject ID\n",
    "    subid = os.path.basename(s)  \n",
    "\n",
    "    # Define directories based on the leap data structure\n",
    "    diffdir = os.path.join(s, 'DWI')  # Main diffusion directory\n",
    "    datadir = os.path.join(diffdir, 'preprocessing')  # Preprocessed data location\n",
    "    dtidir = os.path.join(datadir, 'dti')  # Output folder for DTI processing\n",
    "\n",
    "    # Create folder for DTI processing if it doesn't exist\n",
    "    if not os.path.exists(dtidir):\n",
    "        os.mkdir(dtidir)\n",
    "\n",
    "    # Update filenames based on leap data file structure\n",
    "    bvec_file = os.path.join(datadir, f\"{subid}_MPN_GR_E_TU_C.bvec\")\n",
    "    bval_file = os.path.join(datadir, f\"{subid}_MPN_GR_E_TU_C.bval\")\n",
    "    dwi_file = os.path.join(datadir, f\"{subid}_MPN_GR_E_TU_C.nii.gz\")\n",
    "    mask_file = os.path.join(datadir, f\"{subid}_MPN_GR_E_TU_C_mask.nii.gz\")\n",
    "\n",
    "    # Command for extracting b=1500 volumes\n",
    "    dwiextract_cmd = [\n",
    "        'dwiextract --export_grad_fsl',\n",
    "        datadir + '/dwi_b1500.new_vecs',\n",
    "        datadir + '/dwi_b1500.new_vals',\n",
    "        '-fslgrad',\n",
    "        bvec_file, bval_file,\n",
    "        '-shell 0.0,1500', dwi_file,\n",
    "        datadir + '/dwi_b1500.nii.gz', '-force'\n",
    "    ]\n",
    "\n",
    "    # Command for creating a mask of b=1500 volumes\n",
    "    bet_cmd = [\n",
    "        'bet', datadir + '/dwi_b1500.nii.gz',\n",
    "        datadir + '/dwi_b1500_brain.nii.gz', '-f 0.20 -m -R'\n",
    "    ]\n",
    "\n",
    "    # Command for DTIfit - creating DTI parameters\n",
    "    dtifit_cmd = [\n",
    "        'dtifit',\n",
    "        '-k', datadir + '/dwi_b1500.nii.gz',\n",
    "        '-o', os.path.join(dtidir, f\"{subid}_dti\"),\n",
    "        '-m', datadir + '/dwi_b1500_brain.nii.gz',\n",
    "        '-r', datadir + '/dwi_b1500.new_vecs',\n",
    "        '-b', datadir + '/dwi_b1500.new_vals',\n",
    "        '--sse'\n",
    "    ]\n",
    "\n",
    "    # Join commands and submit process\n",
    "    proc_cmd = \" \".join(dwiextract_cmd) + ' && ' + \" \".join(bet_cmd) + ' && ' + \" \".join(dtifit_cmd)\n",
    "    cmd_qsub = cmd_qsub_base + ['-name', 'LEAP3_dtifit_' + subid, '-command \"' + proc_cmd + '\"']\n",
    "\n",
    "    # Print command and submit process\n",
    "    print('Processing')\n",
    "    print(len(sub_dtifit_ready) - count, 'subjects left for DTIfit')\n",
    "\n",
    "    # Uncomment the line below to run the process\n",
    "#     subprocess.run(' '.join(cmd_qsub), shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    print(' '.join(cmd_qsub))\n",
    "\n",
    "    count += 1\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run TBSS - to extract the FA skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for s in sub_tbss_ready[0:]:\n",
    "    try:\n",
    "        #Define directories needed\n",
    "        subid = os.path.splitext(os.path.basename(s))[0]\n",
    "        # Define directories based on leap data structure\n",
    "        diffdir = os.path.join(s, 'DWI', 'preprocessing')  # Main diffusion directory\n",
    "        dtidir = os.path.join(diffdir, 'dti')  # Output folder for DTI processing\n",
    "        tbssdir = os.path.join(diffdir, 'tbss') #TBSS directory\n",
    "\n",
    "        fa_path_src = os.path.join(dtidir,str(''.join([subid,'_dti_FA.nii.gz']))) #path to the FA image source\n",
    "        fa_path_dst = os.path.join(tbssdir,str(''.join([subid,'_dti_FA.nii.gz']))) #path to the FA image destination\n",
    "\n",
    "        #Create folder for TBSS\n",
    "        if os.path.exists(tbssdir) == False:\n",
    "            os.mkdir(tbssdir)\n",
    "\n",
    "        #We must create a copy of the FA image in the TBSS directory\n",
    "        shutil.copyfile(fa_path_src, fa_path_dst)\n",
    "\n",
    "        # Run TBSS FA\n",
    "        tbss1_cmd = ['cd ' + tbssdir + ' && tbss_1_preproc *.nii.gz']\n",
    "        tbss2_cmd = ['tbss_2_reg -T *.nii.gz']\n",
    "        tbss3_cmd = ['tbss_3_postreg -S *.nii.gz']\n",
    "        tbss4_cmd = ['tbss_4_prestats 0.2 *.nii.gz']\n",
    "\n",
    "        proc_cmd = \"%s\" % str(' '.join(tbss1_cmd) + ' && ' + ' '.join(tbss2_cmd) + ' && ' + ' '.join(tbss3_cmd) + ' && ' + ' '.join(tbss4_cmd))\n",
    "        cmd_qsub = cmd_qsub_base + ['-name', 'LEAP3_tbss_' + subid ,'-command \"', proc_cmd, '\"']  \n",
    "        print('Processing')\n",
    "        print(len(sub_tbss_ready)-count, 'subjects left for TBSS FA')\n",
    "        #Uncomment the line below and run to submit process\n",
    "#         subprocess.run(''.join(proc_cmd), shell=True, stdout = subprocess.DEVNULL, stderr = subprocess.DEVNULL)\n",
    "        print(' '.join(cmd_qsub))\n",
    "        count = count+1\n",
    "    except:\n",
    "            print('error')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features - getting the mean skeleton FA for each tract in the JHU atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts_nr = tuple([\"%d\" %i for i in range(1,51)])\n",
    "param_mean = pd.DataFrame(columns=tracts_nr)\n",
    "param = 'FA'\n",
    "\n",
    "for s in sub_tbss_complete[0:]:\n",
    "    subid = os.path.splitext(os.path.basename(s))[0]\n",
    "    diffdir = os.path.join(s, 'DWI', 'preprocessing')\n",
    "    tbssdir = os.path.join(diffdir, 'tbss')\n",
    "    atlasdir = '/opt/fsl/6.0.5/data/atlases/JHU/JHU-ICBM-labels-1mm'\n",
    "\n",
    "    \n",
    "    # compile command\n",
    "    fslstats_cmd = ['fslstats -K ', atlasdir,' ', tbssdir,'/stats', '/all_',param,'_skeletonised.nii.gz',' -M']  \n",
    "    \n",
    "    #check your command and submit process \n",
    "#     print(''.join(fslstats_cmd))\n",
    "#     uncomment the section below and run to submit process\n",
    "    try:\n",
    "        p = subprocess.Popen(''.join(fslstats_cmd), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) \n",
    "        # get output of the process (i.e. our result)\n",
    "        out, err = p.communicate()\n",
    "        cost = out.decode() #getting the output (which is the feature we want)\n",
    "        cost = tuple(cost.splitlines())\n",
    "        param_mean.loc[subid] = cost #(storing the feature)\n",
    "        progress = (len(param_mean)/len(sub_tbss_complete)*100) # keeping track of progress\n",
    "        print(round(progress,3),'%',end='  ') #print ptogress\n",
    "    except:\n",
    "        print('no')\n",
    "path = str(''.join(['/home/preclineu/ramcir/Desktop/Clinical/data/LEAP3_',param,'_mean.pkl']))\n",
    "param_mean.to_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning labels to the FA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the JHU tract labels\n",
    "jhu_labels_path = '/home/preclineu/ramcir/Desktop/Processing/jhu_labels.csv'\n",
    "jhu_labels = pd.read_csv(jhu_labels_path, delimiter = \";\")\n",
    "jhu_labels = jhu_labels.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickled dataframes containing the diffusion parameters mean from where they were saved\n",
    "fa_mean = pd.read_pickle('/home/preclineu/ramcir/Desktop/Clinical/data/LEAP3_FA_mean.pkl')\n",
    "#rename the rows with the JHU labels \n",
    "fa_mean.columns = ['FA mean of ' + s for s in jhu_labels.label]\n",
    "#Changing datatype to float to ensure easy oeprations with numbers\n",
    "fa_mean = fa_mean.astype('float64') \n",
    "fa_mean.index = fa_mean.index.astype(int)\n",
    "fa_mean.columns = fa_mean.columns.str.replace(\" - \", \"-\")\n",
    "fa_mean.columns = fa_mean.columns.str.replace(\" \", \"_\")\n",
    "#Save dataframe with all extracted DTI IDPs\n",
    "fa_mean.to_pickle(\"/home/preclineu/ramcir/Desktop/Clinical/data/leap_fa_labeled.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare clinical and poligenic score (PGS) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get clinical (and demographic) data with labels\n",
    "leap3_clin_path = '/project_cephfs/3022035.06/LEAP_clinical/LEAP_t1_Core clinical variables_03-09-19-withlabels.xlsx'\n",
    "leap3_clin_data_label = pd.read_excel(leap3_clin_path)\n",
    "leap3_clin_data_label = leap3_clin_data_label.set_index(\"subjects\")\n",
    "leap3_clin_data_label.index = leap3_clin_data_label.index.astype(int)\n",
    "\n",
    "# Get clinical (and demographic) data with numerical values\n",
    "leap3_clin_path = '/project_cephfs/3022035.06/LEAP_clinical/LEAP_t1_Core clinical variables_03-09-19-withvalues.xlsx'\n",
    "leap3_clin_data_val = pd.read_excel(leap3_clin_path)\n",
    "leap3_clin_data_val = leap3_clin_data_val.set_index(\"subjects\")\n",
    "leap3_clin_data_val.index = leap3_clin_data_val.index.astype(int)\n",
    "\n",
    "# Get genetics data and extract PGS\n",
    "leap3_pgs_path = '/project_cephfs/3022035.06/LEAP_genetics/Freeze_V3_LEAP_May2020/Fam_LEAP_FreezeV3_Final.tsv'\n",
    "df = pd.read_csv(leap3_pgs_path, sep='\\t')\n",
    "pgs_columns = pgs_columns = ['participant_id'] + [col for col in df.columns if col.startswith('PGS')]\n",
    "leap3_pgs_data = df[pgs_columns]\n",
    "leap3_pgs_data = leap3_pgs_data.set_index(\"participant_id\")\n",
    "leap3_pgs_data.index = leap3_pgs_data.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PGS_ASD_ipsych_Z</th>\n",
       "      <th>PGS_ADHD_Z</th>\n",
       "      <th>PGS_BMI_Z</th>\n",
       "      <th>PGS_Chronotype_Z</th>\n",
       "      <th>PGS_EduYears_Z</th>\n",
       "      <th>PGS_Epilepsy_Z</th>\n",
       "      <th>PGS_EQ_Z</th>\n",
       "      <th>PGS_Insomnia_Z</th>\n",
       "      <th>PGS_Intelligence_Z</th>\n",
       "      <th>PGS_MDD_Z</th>\n",
       "      <th>...</th>\n",
       "      <th>PGS_xDx_ipsych_Z</th>\n",
       "      <th>PGS_total_brain_Z</th>\n",
       "      <th>PGS_brain_ICV_Z</th>\n",
       "      <th>PGS_brain_accumbens_Z</th>\n",
       "      <th>PGS_brain_amygdala_Z</th>\n",
       "      <th>PGS_brain_caudate_Z</th>\n",
       "      <th>PGS_brain_hippocampus_Z</th>\n",
       "      <th>PGS_brain_pallidum_Z</th>\n",
       "      <th>PGS_brain_putamen_Z</th>\n",
       "      <th>PGS_brain_thalamus_Z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>630147348337</th>\n",
       "      <td>-0.168606</td>\n",
       "      <td>0.027534</td>\n",
       "      <td>-0.231661</td>\n",
       "      <td>-1.865506</td>\n",
       "      <td>-0.262605</td>\n",
       "      <td>0.799300</td>\n",
       "      <td>-0.131653</td>\n",
       "      <td>0.234844</td>\n",
       "      <td>0.483145</td>\n",
       "      <td>-0.293856</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.224060</td>\n",
       "      <td>0.396896</td>\n",
       "      <td>-0.216139</td>\n",
       "      <td>-0.302487</td>\n",
       "      <td>-1.085921</td>\n",
       "      <td>-1.862822</td>\n",
       "      <td>-0.309132</td>\n",
       "      <td>-0.022666</td>\n",
       "      <td>0.243929</td>\n",
       "      <td>0.339258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225703603586</th>\n",
       "      <td>0.509307</td>\n",
       "      <td>1.100314</td>\n",
       "      <td>-0.009208</td>\n",
       "      <td>-1.918326</td>\n",
       "      <td>0.811997</td>\n",
       "      <td>0.584945</td>\n",
       "      <td>-0.329456</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>0.906440</td>\n",
       "      <td>-0.104530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414322</td>\n",
       "      <td>-0.396971</td>\n",
       "      <td>-0.029117</td>\n",
       "      <td>-0.152706</td>\n",
       "      <td>-0.992157</td>\n",
       "      <td>-1.066941</td>\n",
       "      <td>0.586802</td>\n",
       "      <td>0.411587</td>\n",
       "      <td>-0.604917</td>\n",
       "      <td>-0.027757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518377749358</th>\n",
       "      <td>-0.261293</td>\n",
       "      <td>-1.963176</td>\n",
       "      <td>-0.571302</td>\n",
       "      <td>-0.446406</td>\n",
       "      <td>-0.296633</td>\n",
       "      <td>0.219145</td>\n",
       "      <td>-0.097263</td>\n",
       "      <td>1.588458</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>-0.129217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.984691</td>\n",
       "      <td>-0.085626</td>\n",
       "      <td>-1.003052</td>\n",
       "      <td>-0.765302</td>\n",
       "      <td>0.129758</td>\n",
       "      <td>-1.930645</td>\n",
       "      <td>-0.681766</td>\n",
       "      <td>-1.490895</td>\n",
       "      <td>-0.261104</td>\n",
       "      <td>-1.147317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989524720202</th>\n",
       "      <td>-0.038631</td>\n",
       "      <td>0.478857</td>\n",
       "      <td>-1.478981</td>\n",
       "      <td>0.475428</td>\n",
       "      <td>-0.033196</td>\n",
       "      <td>0.597478</td>\n",
       "      <td>-0.487264</td>\n",
       "      <td>-0.660490</td>\n",
       "      <td>-1.163090</td>\n",
       "      <td>0.569518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200231</td>\n",
       "      <td>1.131082</td>\n",
       "      <td>0.266684</td>\n",
       "      <td>1.707148</td>\n",
       "      <td>-0.219151</td>\n",
       "      <td>0.394110</td>\n",
       "      <td>0.248316</td>\n",
       "      <td>0.407355</td>\n",
       "      <td>-0.257268</td>\n",
       "      <td>-0.589293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942056644783</th>\n",
       "      <td>-1.192805</td>\n",
       "      <td>-0.041962</td>\n",
       "      <td>-2.221731</td>\n",
       "      <td>-1.250105</td>\n",
       "      <td>-0.326269</td>\n",
       "      <td>0.637560</td>\n",
       "      <td>-1.415585</td>\n",
       "      <td>-0.246713</td>\n",
       "      <td>-0.956827</td>\n",
       "      <td>-0.720520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385103</td>\n",
       "      <td>1.324179</td>\n",
       "      <td>0.790899</td>\n",
       "      <td>1.173727</td>\n",
       "      <td>-0.320672</td>\n",
       "      <td>0.921688</td>\n",
       "      <td>0.572164</td>\n",
       "      <td>0.293159</td>\n",
       "      <td>-0.717179</td>\n",
       "      <td>-0.024091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186734682586</th>\n",
       "      <td>-0.119630</td>\n",
       "      <td>-1.437292</td>\n",
       "      <td>-0.431690</td>\n",
       "      <td>1.296391</td>\n",
       "      <td>2.144547</td>\n",
       "      <td>-1.518682</td>\n",
       "      <td>-0.873528</td>\n",
       "      <td>-0.705378</td>\n",
       "      <td>0.707114</td>\n",
       "      <td>-0.749350</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.724576</td>\n",
       "      <td>1.890261</td>\n",
       "      <td>2.309389</td>\n",
       "      <td>0.872595</td>\n",
       "      <td>0.748066</td>\n",
       "      <td>1.390126</td>\n",
       "      <td>0.654494</td>\n",
       "      <td>0.295236</td>\n",
       "      <td>-0.328474</td>\n",
       "      <td>0.067464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891768375411</th>\n",
       "      <td>-0.756705</td>\n",
       "      <td>-1.894308</td>\n",
       "      <td>1.037964</td>\n",
       "      <td>1.507187</td>\n",
       "      <td>-0.118813</td>\n",
       "      <td>-0.899910</td>\n",
       "      <td>-0.996857</td>\n",
       "      <td>-0.408852</td>\n",
       "      <td>-1.296046</td>\n",
       "      <td>-0.344933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.883073</td>\n",
       "      <td>1.249325</td>\n",
       "      <td>1.638119</td>\n",
       "      <td>-0.087054</td>\n",
       "      <td>0.230532</td>\n",
       "      <td>1.391857</td>\n",
       "      <td>0.619866</td>\n",
       "      <td>0.854608</td>\n",
       "      <td>0.650712</td>\n",
       "      <td>-1.041993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136124811300</th>\n",
       "      <td>0.015380</td>\n",
       "      <td>0.395286</td>\n",
       "      <td>-0.582276</td>\n",
       "      <td>-0.504632</td>\n",
       "      <td>0.685767</td>\n",
       "      <td>-0.645570</td>\n",
       "      <td>-0.390701</td>\n",
       "      <td>0.438777</td>\n",
       "      <td>0.811069</td>\n",
       "      <td>-2.101191</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.170310</td>\n",
       "      <td>1.464100</td>\n",
       "      <td>1.811596</td>\n",
       "      <td>1.671823</td>\n",
       "      <td>1.800819</td>\n",
       "      <td>2.137234</td>\n",
       "      <td>0.722797</td>\n",
       "      <td>-0.579357</td>\n",
       "      <td>-0.998502</td>\n",
       "      <td>0.989093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125610027898</th>\n",
       "      <td>-1.004392</td>\n",
       "      <td>-1.143594</td>\n",
       "      <td>1.763639</td>\n",
       "      <td>0.408940</td>\n",
       "      <td>-0.031001</td>\n",
       "      <td>2.088288</td>\n",
       "      <td>-0.058887</td>\n",
       "      <td>0.613597</td>\n",
       "      <td>0.803428</td>\n",
       "      <td>0.092231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.732737</td>\n",
       "      <td>-0.657388</td>\n",
       "      <td>-0.851198</td>\n",
       "      <td>-1.633319</td>\n",
       "      <td>-0.773474</td>\n",
       "      <td>-0.277084</td>\n",
       "      <td>-1.204929</td>\n",
       "      <td>-1.265574</td>\n",
       "      <td>0.099306</td>\n",
       "      <td>-0.755755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783260948093</th>\n",
       "      <td>0.269628</td>\n",
       "      <td>-0.833021</td>\n",
       "      <td>0.906434</td>\n",
       "      <td>-0.612144</td>\n",
       "      <td>1.267523</td>\n",
       "      <td>0.349056</td>\n",
       "      <td>0.865005</td>\n",
       "      <td>0.437766</td>\n",
       "      <td>1.076378</td>\n",
       "      <td>1.638846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315450</td>\n",
       "      <td>-0.610841</td>\n",
       "      <td>-0.766626</td>\n",
       "      <td>-0.380913</td>\n",
       "      <td>1.115787</td>\n",
       "      <td>1.183357</td>\n",
       "      <td>-0.241790</td>\n",
       "      <td>-0.082848</td>\n",
       "      <td>-1.185703</td>\n",
       "      <td>0.215574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1566 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                PGS_ASD_ipsych_Z  PGS_ADHD_Z  PGS_BMI_Z  PGS_Chronotype_Z  \\\n",
       "participant_id                                                              \n",
       "630147348337           -0.168606    0.027534  -0.231661         -1.865506   \n",
       "225703603586            0.509307    1.100314  -0.009208         -1.918326   \n",
       "518377749358           -0.261293   -1.963176  -0.571302         -0.446406   \n",
       "989524720202           -0.038631    0.478857  -1.478981          0.475428   \n",
       "942056644783           -1.192805   -0.041962  -2.221731         -1.250105   \n",
       "...                          ...         ...        ...               ...   \n",
       "186734682586           -0.119630   -1.437292  -0.431690          1.296391   \n",
       "891768375411           -0.756705   -1.894308   1.037964          1.507187   \n",
       "136124811300            0.015380    0.395286  -0.582276         -0.504632   \n",
       "125610027898           -1.004392   -1.143594   1.763639          0.408940   \n",
       "783260948093            0.269628   -0.833021   0.906434         -0.612144   \n",
       "\n",
       "                PGS_EduYears_Z  PGS_Epilepsy_Z  PGS_EQ_Z  PGS_Insomnia_Z  \\\n",
       "participant_id                                                             \n",
       "630147348337         -0.262605        0.799300 -0.131653        0.234844   \n",
       "225703603586          0.811997        0.584945 -0.329456        0.010822   \n",
       "518377749358         -0.296633        0.219145 -0.097263        1.588458   \n",
       "989524720202         -0.033196        0.597478 -0.487264       -0.660490   \n",
       "942056644783         -0.326269        0.637560 -1.415585       -0.246713   \n",
       "...                        ...             ...       ...             ...   \n",
       "186734682586          2.144547       -1.518682 -0.873528       -0.705378   \n",
       "891768375411         -0.118813       -0.899910 -0.996857       -0.408852   \n",
       "136124811300          0.685767       -0.645570 -0.390701        0.438777   \n",
       "125610027898         -0.031001        2.088288 -0.058887        0.613597   \n",
       "783260948093          1.267523        0.349056  0.865005        0.437766   \n",
       "\n",
       "                PGS_Intelligence_Z  PGS_MDD_Z  ...  PGS_xDx_ipsych_Z  \\\n",
       "participant_id                                 ...                     \n",
       "630147348337              0.483145  -0.293856  ...         -1.224060   \n",
       "225703603586              0.906440  -0.104530  ...         -0.414322   \n",
       "518377749358              0.006686  -0.129217  ...         -0.984691   \n",
       "989524720202             -1.163090   0.569518  ...          0.200231   \n",
       "942056644783             -0.956827  -0.720520  ...          0.385103   \n",
       "...                            ...        ...  ...               ...   \n",
       "186734682586              0.707114  -0.749350  ...         -1.724576   \n",
       "891768375411             -1.296046  -0.344933  ...         -0.883073   \n",
       "136124811300              0.811069  -2.101191  ...         -2.170310   \n",
       "125610027898              0.803428   0.092231  ...         -0.732737   \n",
       "783260948093              1.076378   1.638846  ...          0.315450   \n",
       "\n",
       "                PGS_total_brain_Z  PGS_brain_ICV_Z  PGS_brain_accumbens_Z  \\\n",
       "participant_id                                                              \n",
       "630147348337             0.396896        -0.216139              -0.302487   \n",
       "225703603586            -0.396971        -0.029117              -0.152706   \n",
       "518377749358            -0.085626        -1.003052              -0.765302   \n",
       "989524720202             1.131082         0.266684               1.707148   \n",
       "942056644783             1.324179         0.790899               1.173727   \n",
       "...                           ...              ...                    ...   \n",
       "186734682586             1.890261         2.309389               0.872595   \n",
       "891768375411             1.249325         1.638119              -0.087054   \n",
       "136124811300             1.464100         1.811596               1.671823   \n",
       "125610027898            -0.657388        -0.851198              -1.633319   \n",
       "783260948093            -0.610841        -0.766626              -0.380913   \n",
       "\n",
       "                PGS_brain_amygdala_Z  PGS_brain_caudate_Z  \\\n",
       "participant_id                                              \n",
       "630147348337               -1.085921            -1.862822   \n",
       "225703603586               -0.992157            -1.066941   \n",
       "518377749358                0.129758            -1.930645   \n",
       "989524720202               -0.219151             0.394110   \n",
       "942056644783               -0.320672             0.921688   \n",
       "...                              ...                  ...   \n",
       "186734682586                0.748066             1.390126   \n",
       "891768375411                0.230532             1.391857   \n",
       "136124811300                1.800819             2.137234   \n",
       "125610027898               -0.773474            -0.277084   \n",
       "783260948093                1.115787             1.183357   \n",
       "\n",
       "                PGS_brain_hippocampus_Z  PGS_brain_pallidum_Z  \\\n",
       "participant_id                                                  \n",
       "630147348337                  -0.309132             -0.022666   \n",
       "225703603586                   0.586802              0.411587   \n",
       "518377749358                  -0.681766             -1.490895   \n",
       "989524720202                   0.248316              0.407355   \n",
       "942056644783                   0.572164              0.293159   \n",
       "...                                 ...                   ...   \n",
       "186734682586                   0.654494              0.295236   \n",
       "891768375411                   0.619866              0.854608   \n",
       "136124811300                   0.722797             -0.579357   \n",
       "125610027898                  -1.204929             -1.265574   \n",
       "783260948093                  -0.241790             -0.082848   \n",
       "\n",
       "                PGS_brain_putamen_Z  PGS_brain_thalamus_Z  \n",
       "participant_id                                             \n",
       "630147348337               0.243929              0.339258  \n",
       "225703603586              -0.604917             -0.027757  \n",
       "518377749358              -0.261104             -1.147317  \n",
       "989524720202              -0.257268             -0.589293  \n",
       "942056644783              -0.717179             -0.024091  \n",
       "...                             ...                   ...  \n",
       "186734682586              -0.328474              0.067464  \n",
       "891768375411               0.650712             -1.041993  \n",
       "136124811300              -0.998502              0.989093  \n",
       "125610027898               0.099306             -0.755755  \n",
       "783260948093              -1.185703              0.215574  \n",
       "\n",
       "[1566 rows x 24 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leap3_pgs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the clinical with the DTI data\n",
    "data_lab = fa_mean.merge(leap3_clin_data_label, left_index=True, right_index=True, how=\"inner\")\n",
    "data_val = fa_mean.merge(leap3_clin_data_val, left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "# Create a column 'sitenum' for the adaptation of the pre-existing normative model\n",
    "# Rename the numerical 't1_site' in data_val to 'sitenum'\n",
    "leap3_fa_clin = data_val.rename(columns={'t1_site': 'sitenum'})\n",
    "\n",
    "# Add the label values of 't1_site' from data_lab as a new column 'site'\n",
    "leap3_fa_clin['site'] = data_val['t1_site'] = 'LEAP3_' + data_lab['t1_site'].astype(str)\n",
    "\n",
    "# Merge FA, clinical and PGS data\n",
    "leap3_fa_clin_pgs = leap3_fa_clin.merge(leap3_pgs_data, left_index=True, right_index=True, how=\"inner\")\n",
    "\n",
    "# Remove missing values\n",
    "leap3_fa_clin_pgs_clean = leap3_fa_clin_pgs.dropna(axis=1)\n",
    "\n",
    "# Save \n",
    "leap3_fa_clin_pgs_clean.to_pickle(\"/home/preclineu/ramcir/Desktop/Clinical/data/leap3_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a closer look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis Counts:\n",
      " 2    72\n",
      "1    51\n",
      "Name: t1_diagnosis, dtype: int64\n",
      "\n",
      "Sex Counts:\n",
      "  1    87\n",
      "-1    36\n",
      "Name: t1_sex, dtype: int64\n",
      "\n",
      "Age Distribution:\n",
      " (6.544, 8.87]       11\n",
      "(8.87, 11.172]      21\n",
      "(11.172, 13.475]    18\n",
      "(13.475, 15.777]    21\n",
      "(15.777, 18.079]    17\n",
      "(18.079, 20.382]    15\n",
      "(20.382, 22.684]     7\n",
      "(22.684, 24.987]     5\n",
      "(24.987, 27.289]     3\n",
      "(27.289, 29.592]     5\n",
      "Name: t1_ageyrs, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t1_drugclass_1</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_drugclass_2</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_drugclass_3</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t1_handedness</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NaN Count\n",
       "t1_drugclass_1         96\n",
       "t1_drugclass_2        115\n",
       "t1_drugclass_3        122\n",
       "t1_handedness           6"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts for categorical columns\n",
    "diagnosis_counts = leap3_fa_clin_pgs['t1_diagnosis'].value_counts()\n",
    "sex_counts = leap3_fa_clin_pgs['t1_sex'].value_counts()\n",
    "\n",
    "# For age, bin the ages into intervals and then count\n",
    "age_bins = pd.cut(leap3_fa_clin_pgs['t1_ageyrs'], bins=10)  # 10 bins for age ranges\n",
    "age_counts = age_bins.value_counts().sort_index()\n",
    "\n",
    "# Count NaN values in each column and filter only non-zero counts\n",
    "nan_counts = leap3_fa_clin_pgs.isna().sum()\n",
    "nan_counts_filtered = nan_counts[nan_counts > 0]\n",
    "\n",
    "# Convert to DataFrame for better display\n",
    "nan_counts_df = nan_counts_filtered.to_frame(name=\"NaN Count\")\n",
    "\n",
    "# Print the value counts\n",
    "print(\"Diagnosis Counts:\\n\", diagnosis_counts)\n",
    "print(\"\\nSex Counts:\\n\", sex_counts)\n",
    "print(\"\\nAge Distribution:\\n\", age_counts)\n",
    "nan_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Min Value  Max Value\n",
      "FA_mean_of_Middle_cerebellar_peduncle                0.459639   0.617263\n",
      "FA_mean_of_Pontine_crossing_tract                    0.432076   0.590094\n",
      "FA_mean_of_Genu_of_corpus_callosum                   0.600662   0.822054\n",
      "FA_mean_of_Body_of_corpus_callosum                   0.562495   0.803812\n",
      "FA_mean_of_Splenium_of_corpus_callosum               0.485674   0.856033\n",
      "FA_mean_of_Fornix-column_and_body                    0.292781   0.739259\n",
      "FA_mean_of_Corticospinal_tract_R                     0.477062   0.660118\n",
      "FA_mean_of_Corticospinal_tract_L                     0.494385   0.706040\n",
      "FA_mean_of_Medial_lemniscus_R                        0.428497   0.705753\n",
      "FA_mean_of_Medial_lemniscus_L                        0.482546   0.692561\n",
      "FA_mean_of_Inferior_cerebellar_peduncle_R            0.349450   0.641426\n",
      "FA_mean_of_Inferior_cerebellar_peduncle_L            0.319756   0.646226\n",
      "FA_mean_of_Superior_cerebellar_peduncle_R            0.470121   0.732941\n",
      "FA_mean_of_Superior_cerebellar_peduncle_L            0.515332   0.744648\n",
      "FA_mean_of_Cerebral_peduncle_R                       0.624007   0.792673\n",
      "FA_mean_of_Cerebral_peduncle_L                       0.636544   0.790032\n",
      "FA_mean_of_Anterior_limb_of_internal_capsule_R       0.564736   0.684387\n",
      "FA_mean_of_Anterior_limb_of_internal_capsule_L       0.530780   0.660950\n",
      "FA_mean_of_Posterior_limb_of_internal_capsule_R      0.605700   0.782312\n",
      "FA_mean_of_Posterior_limb_of_internal_capsule_L      0.631386   0.772627\n",
      "FA_mean_of_Retrolenticular_part_of_internal_cap...   0.539578   0.688676\n",
      "FA_mean_of_Retrolenticular_part_of_internal_cap...   0.539578   0.711516\n",
      "FA_mean_of_Anterior_corona_radiata_R                 0.384656   0.578048\n",
      "FA_mean_of_Anterior_corona_radiata_L                 0.412029   0.578201\n",
      "FA_mean_of_Superior_corona_radiata_R                 0.452242   0.639268\n",
      "FA_mean_of_Superior_corona_radiata_L                 0.448664   0.700428\n",
      "FA_mean_of_Posterior_corona_radiata_R                0.425790   0.592943\n",
      "FA_mean_of_Posterior_corona_radiata_L                0.429095   0.596201\n",
      "FA_mean_of_Posterior_thalamic_radiation_R            0.479072   0.702596\n",
      "FA_mean_of_Posterior_thalamic_radiation_L            0.503354   0.711564\n",
      "FA_mean_of_Sagittal_stratum_R                        0.461897   0.654437\n",
      "FA_mean_of_Sagittal_stratum_L                        0.464505   0.665051\n",
      "FA_mean_of_External_capsule_R                        0.369600   0.511706\n",
      "FA_mean_of_External_capsule_L                        0.391004   0.534616\n",
      "FA_mean_of_Cingulum-cingulate_gyrus_R                0.459284   0.697650\n",
      "FA_mean_of_Cingulum-cingulate_gyrus_L                0.497764   0.732472\n",
      "FA_mean_of_Cingulum-hippocampus_R                    0.395995   0.662814\n",
      "FA_mean_of_Cingulum-hippocampus_L                    0.000000   0.663142\n",
      "FA_mean_of_Fornix_cres-Stria_terminalis_R            0.454148   0.676220\n",
      "FA_mean_of_Fornix_cres-Stria_terminalis_L            0.478367   0.691221\n",
      "FA_mean_of_Superior_longitudinal_fasciculus_R        0.412164   0.612268\n",
      "FA_mean_of_Superior_longitudinal_fasciculus_L        0.346937   0.619251\n",
      "FA_mean_of_Superior_fronto-occipital_fasciculus_R    0.421286   0.646778\n",
      "FA_mean_of_Superior_fronto-occipital_fasciculus_L    0.398813   0.682620\n",
      "FA_mean_of_Inferior_fronto-occipital_fasciculus_R    0.368882   0.635902\n",
      "FA_mean_of_Inferior_fronto-occipital_fasciculus_L    0.351629   0.620399\n",
      "FA_mean_of_Uncinate_fasciculus_R                     0.372358   0.763683\n",
      "FA_mean_of_Uncinate_fasciculus_L                     0.312575   0.658811\n",
      "FA_mean_of_Tapetum_R                                 0.000000   0.758569\n",
      "FA_mean_of_Tapetum_L                                 0.000000   0.816742\n"
     ]
    }
   ],
   "source": [
    "# Find the minimum and maximum values for each column\n",
    "min_values = fa_mean.min()\n",
    "max_values = fa_mean.max()\n",
    "\n",
    "# Combine the results into a DataFrame for clarity\n",
    "range_df = pd.DataFrame({'Min Value': min_values, 'Max Value': max_values})\n",
    "\n",
    "# Display the result\n",
    "print(range_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects with missing files or directories:\n",
      "Subject 325027333124 is missing: 325027333124_MPN_GR_E_TU_C.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Base directory where subjects are stored\n",
    "BASE_DIR = \"/project_cephfs/3022035.06/LEAP_wave3\"\n",
    "\n",
    "# List of required directories\n",
    "required_dirs = [\"dtifit\", \"tbss\"]\n",
    "\n",
    "# List of required file suffixes\n",
    "required_files = [\n",
    "    \"_MPN_GR_E_TU_C.bval\",\n",
    "    \"_MPN_GR_E_TU_C.bvec\",\n",
    "    \"_MPN_GR_E_TU_C.nii.gz\",\n",
    "    \"_MPN_GR_E_TU_C_mask.nii.gz\"\n",
    "]\n",
    "\n",
    "# Dictionary to store missing files per subject\n",
    "missing_data = {}\n",
    "\n",
    "# Loop through subject directories\n",
    "for subject in os.listdir(BASE_DIR):\n",
    "    subject_path = os.path.join(BASE_DIR, subject)\n",
    "    \n",
    "    # Ensure it's a directory and subject ID is numeric\n",
    "    if os.path.isdir(subject_path) and subject.isdigit():\n",
    "        preprocessing_path = os.path.join(subject_path, \"DWI\", \"preprocessing\")\n",
    "\n",
    "        # Check if preprocessing directory exists\n",
    "        if not os.path.exists(preprocessing_path):\n",
    "            missing_data[subject] = [\"Missing preprocessing directory\"]\n",
    "            continue  # No need to check further for this subject\n",
    "\n",
    "        # Check for missing directories\n",
    "        missing_items = [\n",
    "            dir_name for dir_name in required_dirs\n",
    "            if not os.path.isdir(os.path.join(preprocessing_path, dir_name))\n",
    "        ]\n",
    "\n",
    "        # Check for missing files\n",
    "        for file_suffix in required_files:\n",
    "            expected_file = os.path.join(preprocessing_path, f\"{subject}{file_suffix}\")\n",
    "            if not os.path.isfile(expected_file):\n",
    "                missing_items.append(os.path.basename(expected_file))\n",
    "\n",
    "        # Store missing items if any\n",
    "        if missing_items:\n",
    "            missing_data[subject] = missing_items\n",
    "\n",
    "# Display results\n",
    "if missing_data:\n",
    "    print(\"Subjects with missing files or directories:\")\n",
    "    for subject, missing_items in missing_data.items():\n",
    "        print(f\"Subject {subject} is missing: {', '.join(missing_items)}\")\n",
    "else:\n",
    "    print(\"All subjects have the required files and directories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
