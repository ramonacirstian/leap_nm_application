{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEAP Wave 1,2 and 3 - sorting through missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import subprocess\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import xmltodict\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "#define data directory\n",
    "maindir = '/project_cephfs/3022035.06/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview DTI data across all 3 waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 351 subjects with dtifit directory present in LEAP_wave1.\n",
      "Found 213 subjects with dtifit directory present in LEAP_wave2.\n",
      "Found 156 subjects with dtifit directory present in LEAP_wave3.\n"
     ]
    }
   ],
   "source": [
    "# Enumerate leap wave directory names\n",
    "leap_waves = ['LEAP_wave1', 'LEAP_wave2', 'LEAP_wave3']\n",
    "\n",
    "# Dictionary to store results for each wave\n",
    "dtifit_presence = {}\n",
    "\n",
    "# Loop through each LEAP wave\n",
    "for wave in leap_waves:\n",
    "    rootdir = os.path.join(maindir, wave)\n",
    "\n",
    "    # Get all subject directories (assuming numeric IDs)\n",
    "    sub_dirs = [d for d in glob.glob(os.path.join(rootdir, '[0-9]*'))]\n",
    "    sub_ids = [os.path.basename(d) for d in sub_dirs]\n",
    "\n",
    "    # Find subjects with dtifit directory present\n",
    "    dtifit_presence[wave] = [\n",
    "        subid for subid, subpath in zip(sub_ids, sub_dirs)\n",
    "        if os.path.exists(os.path.join(subpath, 'DWI', 'preprocessing', 'dtifit'))\n",
    "    ]\n",
    "\n",
    "    # Print summary\n",
    "    print(f'Found {len(dtifit_presence[wave])} subjects with dtifit directory present in {wave}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store DataFrames for each wave\n",
    "dtifit_dfs = {}\n",
    "\n",
    "# Loop through each LEAP wave and store subject IDs in a DataFrame\n",
    "for wave in leap_waves:\n",
    "    dtifit_dfs[wave] = pd.DataFrame({\"subjects\": dtifit_presence[wave]})\n",
    "\n",
    "# Unpack individual DataFrames for easier access\n",
    "df_dtifit_wave1 = dtifit_dfs[\"LEAP_wave1\"]\n",
    "df_dtifit_wave1['subjects'] = df_dtifit_wave1['subjects'].astype(int)\n",
    "df_dtifit_wave2 = dtifit_dfs[\"LEAP_wave2\"]\n",
    "df_dtifit_wave2['subjects'] = df_dtifit_wave2['subjects'].astype(int)\n",
    "df_dtifit_wave3 = dtifit_dfs[\"LEAP_wave3\"]\n",
    "df_dtifit_wave3['subjects'] = df_dtifit_wave3['subjects'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview Clinical data across all 3 waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_symptoms = [\n",
    "    \"adi_social_total\",  # Social interaction deficits (ADI-R)\n",
    "    \"adi_communication_total\",  # Communication deficits (ADI-R)\n",
    "    \"adi_rrb_total\",  # Restricted & repetitive behaviors (ADI-R)\n",
    "    \"css_total\",  # Overall autism severity (Calibrated Severity Score)\n",
    "    \"sa_css\",  # Social Affect severity (Calibrated Severity Score)\n",
    "    \"rrb_css\",  # Restricted & Repetitive Behaviors severity (Calibrated Severity Score)\n",
    "    \"srs_tscore_combined\",  # Social responsiveness difficulties (SRS Total Score)\n",
    "    \"adhd_inattentiv_parent\",  # Parent-reported inattention symptoms (ADHD)\n",
    "    \"adhd_hyperimpul_parent\",  # Parent-reported hyperactivity/impulsivity symptoms (ADHD)\n",
    "    \"rbs_total\",  # Total repetitive behaviors (Repetitive Behavior Scale-Revised, RBS-R)\n",
    "    \"sdq_total_difficulties_p\",  # Total behavioral difficulties (Strengths & Difficulties Questionnaire, SDQ)\n",
    "    \"beck_anx_adulta_self\",  # Self-reported anxiety (Beck Anxiety Inventory, BAI)\n",
    "    \"beck_dep_adulta_self\",  # Self-reported depression (Beck Depression Inventory, BDI)\n",
    "    \"ssp_total\",  # Total sensory processing difficulties (Short Sensory Profile, SSP)\n",
    "    \"ssp_hype\"  # Hyperresponsiveness to sensory stimuli (Sensory Processing Issue)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load clinical data wave 1\n",
    "# leap1_clin_path = '/project_cephfs/3022035.06/LEAP_clinical/LEAP_t1_Core clinical variables_03-09-19-withvalues.xlsx'\n",
    "# df1_clinical = pd.read_excel(leap1_clin_path)\n",
    "# df1_clinical.replace([999, 777, '999', '777', np.nan], pd.NA, inplace=True)\n",
    "# df1_clinical['subjects'] = df1_clinical['subjects'].astype(int)\n",
    "# df1_clinical = df1_clinical[df1_clinical['subjects'].isin(df_dtifit_wave1['subjects'])]\n",
    "# variables_df1 = df1_clinical.columns.tolist()\n",
    "\n",
    "# # Load clinical data wave 2\n",
    "# leap2_clin_path = '/project_cephfs/3022035.06/LEAP_clinical/LEAP_t2_Core clinical variables_03-09-19-withvalues.xlsx'\n",
    "# df2_clinical = pd.read_excel(leap2_clin_path)\n",
    "# df2_clinical.replace([999, 777, '999', '777', np.nan], pd.NA, inplace=True)\n",
    "# df2_clinical = df2_clinical[df2_clinical['t2_absence'].isna()]\n",
    "# df2_clinical['subjects'] = df2_clinical['subjects'].astype(int)\n",
    "# df2_clinical = df2_clinical[df2_clinical['subjects'].isin(df_dtifit_wave2['subjects'])]\n",
    "# variables_df2 = df2_clinical.columns.tolist()\n",
    "\n",
    "# # Load clinical data wave 3\n",
    "# leap3_clin_path = '/home/preclineu/ramcir/Desktop/Clinical/data/LEAP_T3_CoreClinicalVariables_fixed.tsv'\n",
    "# df3_clinical = pd.read_csv(leap3_clin_path, sep='\\t')\n",
    "# df3_clinical.replace([999, 777, '999', '777', np.nan], pd.NA, inplace=True)\n",
    "# df3_clinical = df3_clinical[df3_clinical['t3_absence'].isna()]\n",
    "# df3_clinical['subjects'] = df3_clinical['subjects'].astype(int)\n",
    "# df3_clinical = df3_clinical[df3_clinical['subjects'].isin(df_dtifit_wave3['subjects'])]\n",
    "# variables_df3 = df3_clinical.columns.tolist()\n",
    "\n",
    "# # Join waves\n",
    "# df12_clinical= df1_clinical.set_index(\"subjects\").join(df2_clinical.set_index(\"subjects\"), how=\"inner\")\n",
    "# df123_clinical= df12_clinical.join(df3_clinical.set_index(\"subjects\"), how=\"inner\")\n",
    "# # Calculate time lapse between visits\n",
    "# df123_clinical[\"t1_t2_lapse\"] = df123_clinical[\"t2_ageyrs\"] - df123_clinical[\"t1_ageyrs\"]\n",
    "# df123_clinical[\"t2_t3_lapse\"] = df123_clinical[\"t3_ageyrs\"] - df123_clinical[\"t2_ageyrs\"]\n",
    "# df123_clinical[\"t1_t3_lapse\"] = df123_clinical[\"t3_ageyrs\"] - df123_clinical[\"t1_ageyrs\"]\n",
    "# # Calculate the mean lapse for each time window\n",
    "# mean_t1_t2_lapse = df123_clinical[\"t1_t2_lapse\"].mean()\n",
    "# mean_t2_t3_lapse = df123_clinical[\"t2_t3_lapse\"].mean()\n",
    "# mean_t1_t3_lapse = df123_clinical[\"t1_t3_lapse\"].mean()\n",
    "# # Display the results\n",
    "# print(f\"Mean T1-T2 Lapse: {mean_t1_t2_lapse:.2f} years\")\n",
    "# print(f\"Mean T2-T3 Lapse: {mean_t2_t3_lapse:.2f} years\")\n",
    "# print(f\"Mean T1-T3 Lapse: {mean_t1_t3_lapse:.2f} years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for clinical data\n",
    "clinical_paths = {\n",
    "    \"wave1\": \"/project_cephfs/3022035.06/LEAP_clinical/LEAP_t1_Core clinical variables_03-09-19-withvalues.xlsx\",\n",
    "    \"wave2\": \"/project_cephfs/3022035.06/LEAP_clinical/LEAP_t2_Core clinical variables_03-09-19-withvalues.xlsx\",\n",
    "    \"wave3\": \"/home/preclineu/ramcir/Desktop/Clinical/data/LEAP_T3_CoreClinicalVariables_fixed.tsv\"\n",
    "}\n",
    "\n",
    "# Ensure DTI dataframes are loaded before running\n",
    "dtifit_waves = {\n",
    "    \"wave1\": df_dtifit_wave1,\n",
    "    \"wave2\": df_dtifit_wave2,\n",
    "    \"wave3\": df_dtifit_wave3\n",
    "}\n",
    "\n",
    "# Absence column names for filtering\n",
    "absence_cols = {\"wave1\": \"t1_absence\", \"wave2\": \"t2_absence\", \"wave3\": \"t3_absence\"}\n",
    "\n",
    "# Dictionary to store cleaned clinical data, variable names, participant counts, and absence reasons\n",
    "clinical_data = {}\n",
    "variables = {}\n",
    "initial_participant_counts = {}\n",
    "filtered_participant_counts = {}\n",
    "absence_reasons = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process each wave\n",
    "for wave, path in clinical_paths.items():\n",
    "    # Load data (Excel for wave1 & wave2, TSV for wave3)\n",
    "    df = pd.read_excel(path) if path.endswith(\".xlsx\") else pd.read_csv(path, sep=\"\\t\")\n",
    "\n",
    "    # Replace invalid values with NA\n",
    "    df.replace([999, 777, \"999\", \"777\", np.nan], pd.NA, inplace=True)\n",
    "\n",
    "    # Store original participant count before filtering\n",
    "    initial_participant_counts[wave] = len(df)\n",
    "\n",
    "    # Retrieve and store absence reasons if applicable\n",
    "    if absence_cols[wave] in df.columns:\n",
    "        absence_counts = df[absence_cols[wave]].value_counts(dropna=True)\n",
    "        absence_reasons[wave] = absence_counts.head(10).to_dict()  # Keep only top 10\n",
    "        # Remove absent subjects\n",
    "        df = df[df[absence_cols[wave]].isna()]\n",
    "    else:\n",
    "        absence_reasons[wave] = \"No absence column for this wave\"\n",
    "\n",
    "    # Convert 'subjects' to int and filter by DTI presence\n",
    "    df[\"subjects\"] = df[\"subjects\"].astype(int)\n",
    "    df = df[df[\"subjects\"].isin(dtifit_waves[wave][\"subjects\"])]\n",
    "\n",
    "    # Store cleaned dataframe and variable names\n",
    "    clinical_data[wave] = df\n",
    "    variables[wave] = df.columns.tolist()\n",
    "\n",
    "    # Store final participant count after filtering\n",
    "    filtered_participant_counts[wave] = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all waves on 'subjects'\n",
    "df_clinical_combined = clinical_data[\"wave1\"].set_index(\"subjects\") \\\n",
    "    .join(clinical_data[\"wave2\"].set_index(\"subjects\"), how=\"inner\") \\\n",
    "    .join(clinical_data[\"wave3\"].set_index(\"subjects\"), how=\"inner\")\n",
    "\n",
    "# Calculate time lapse between visits\n",
    "df_clinical_combined[\"t1_t2_lapse\"] = df_clinical_combined[\"t2_ageyrs\"] - df_clinical_combined[\"t1_ageyrs\"]\n",
    "df_clinical_combined[\"t2_t3_lapse\"] = df_clinical_combined[\"t3_ageyrs\"] - df_clinical_combined[\"t2_ageyrs\"]\n",
    "df_clinical_combined[\"t1_t3_lapse\"] = df_clinical_combined[\"t3_ageyrs\"] - df_clinical_combined[\"t1_ageyrs\"]\n",
    "\n",
    "# Calculate mean lapse times\n",
    "mean_lapses = {\n",
    "    \"Mean T1-T2 Lapse\": df_clinical_combined[\"t1_t2_lapse\"].mean(),\n",
    "    \"Mean T2-T3 Lapse\": df_clinical_combined[\"t2_t3_lapse\"].mean(),\n",
    "    \"Mean T1-T3 Lapse\": df_clinical_combined[\"t1_t3_lapse\"].mean()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Participant Counts (Before Filtering for Absence & DTI):\n",
      "Participants in Wave1: 763\n",
      "Participants in Wave2: 763\n",
      "Participants in Wave3: 309\n",
      "\n",
      "Filtered Participant Counts (After Absence Removal & DTI Filtering):\n",
      "Participants in Wave1: 351\n",
      "Participants in Wave2: 213\n",
      "Participants in Wave3: 153\n",
      "\n",
      "Top 10 Reasons for Absence (before filtering):\n",
      "\n",
      "Wave1:\n",
      "  No absence column for this wave\n",
      "\n",
      "Wave2:\n",
      "  Not invited for T2: Rome participant: 42\n",
      "  At BL: Late schedule D recruits: BL only: 30\n",
      "  Unable to make contact with participant: 28\n",
      "  Burden is too high: 22\n",
      "  No specific reason given or recorded: 19\n",
      "  Personal circumstances: 17\n",
      "  Not liking (an aspect of) the study: 17\n",
      "  Not invited back: 9\n",
      "  Busy with job/school: 6\n",
      "  At BL: Only some records (may be kept): 4\n",
      "\n",
      "Wave3:\n",
      "  11: 1\n",
      "  10: 1\n",
      "\n",
      "Mean Lapse Times:\n",
      "Mean T1-T2 Lapse: 1.47 years\n",
      "Mean T2-T3 Lapse: 5.71 years\n",
      "Mean T1-T3 Lapse: 7.18 years\n"
     ]
    }
   ],
   "source": [
    "# Print participant counts before and after filtering\n",
    "print(\"\\nInitial Participant Counts (Before Filtering for Absence & DTI):\")\n",
    "for wave, count in initial_participant_counts.items():\n",
    "    print(f\"Participants in {wave.capitalize()}: {count}\")\n",
    "\n",
    "print(\"\\nFiltered Participant Counts (After Absence Removal & DTI Filtering):\")\n",
    "for wave, count in filtered_participant_counts.items():\n",
    "    print(f\"Participants in {wave.capitalize()}: {count}\")\n",
    "\n",
    "# Print top 10 absence reasons before filtering\n",
    "print(\"\\nTop 10 Reasons for Absence (before filtering):\")\n",
    "for wave, reasons in absence_reasons.items():\n",
    "    print(f\"\\n{wave.capitalize()}:\")\n",
    "    if isinstance(reasons, dict):\n",
    "        for reason, count in reasons.items():\n",
    "            print(f\"  {reason}: {count}\")\n",
    "    else:\n",
    "        print(f\"  {reasons}\")\n",
    "\n",
    "# Print mean lapse times\n",
    "print(\"\\nMean Lapse Times:\")\n",
    "for key, value in mean_lapses.items():\n",
    "    print(f\"{key}: {value:.2f} years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove prefixes (t1_, t2_, t3_) from variable names for comparison\n",
    "# variables_df1_cleaned = {var.split('_', 1)[1] for var in variables_df1 if '_' in var}\n",
    "# variables_df2_cleaned = {var.split('_', 1)[1] for var in variables_df2 if '_' in var}\n",
    "# variables_df3_cleaned = {var.split('_', 1)[1] for var in variables_df3 if '_' in var}\n",
    "# # Find common variables present in all three waves\n",
    "# common_variables12 = variables_df1_cleaned & variables_df2_cleaned\n",
    "# common_variables23 = variables_df2_cleaned & variables_df3_cleaned\n",
    "# common_variables13 = variables_df1_cleaned & variables_df3_cleaned \n",
    "# common_variables123 = variables_df1_cleaned & variables_df2_cleaned & variables_df3_cleaned\n",
    "# # Find unique variables in each wave by subtracting the common ones\n",
    "# unique_variables1 = variables_df1_cleaned - (variables_df2_cleaned | variables_df3_cleaned)\n",
    "# unique_variables2 = variables_df2_cleaned - (variables_df1_cleaned | variables_df3_cleaned)\n",
    "# unique_variables3 = variables_df3_cleaned - (variables_df1_cleaned | variables_df2_cleaned)\n",
    "# # Display counts of variables\n",
    "# print(f\"Number of overlapping variables W1-W2: {len(common_variables12)}\")\n",
    "# print(f\"Number of overlapping variables W2-W3: {len(common_variables23)}\")\n",
    "# print(f\"Number of overlapping variables W1-W3: {len(common_variables13)}\")\n",
    "# print(f\"Number of overlapping variables in all three waves: {len(common_variables123)}\")\n",
    "# print(f\"Number of unique variables in W1: {len(unique_variables1)}\")\n",
    "# print(f\"Number of unique variables in W2: {len(unique_variables2)}\")\n",
    "# print(f\"Number of unique variables in W3: {len(unique_variables3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ca913 td {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ca913\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ca913_level0_col0\" class=\"col_heading level0 col0\" >Comparison</th>\n",
       "      <th id=\"T_ca913_level0_col1\" class=\"col_heading level0 col1\" >Variable Count</th>\n",
       "      <th id=\"T_ca913_level0_col2\" class=\"col_heading level0 col2\" >Variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ca913_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ca913_row0_col0\" class=\"data row0 col0\" >W1-W2</td>\n",
       "      <td id=\"T_ca913_row0_col1\" class=\"data row0 col1\" >58</td>\n",
       "      <td id=\"T_ca913_row0_col2\" class=\"data row0 col2\" >sdq_emotional_p, iqwechrawscores_vo_raw, iqwechrawscores_si_t, ssp_audfilt, iqwechrawscores_vo_t, rbs_total, iqwechrawscores_bd_t, ssp_tactile, site, vabsdscoresc_dss, drugclass_3, ssp_total, iqtype, adhd_hyperimpul_parent, iqwechrawscores_mr_t, iqwechrawscores_si_raw, vabsabcabc_standard, vabsdscoresd_dss, sdq_internalising_p, iqwechrawscores_pc_raw, css_total, drugclass_1, srs_tscore_self, ssp_hype, drugclass_2, srs_tscore, ssp_lowenergy, sdq_externalising_p, ssp_prorated, age, srs_tscore_combined, srs_rawscore_self, sdq_prosocial_p, sa_css, sdq_peer_p, sdq_total_difficulties_p, ageyrs, iqwechrawscores_mr_raw, sdq_impact_p, ssp_underrespo_mod, ssp_visualaudisens, rrb_css, med_use, ssp_taste, sdq_conduct_p, iqwechrawscores_pc_t, vabsdscoress_dss, srs_rawscore, iqwechrawscores_bd_raw, iqwechrawscores_vp_raw, ssp_underresp, srs_rawscore_combined, adhd_inattentiv_parent, sdq_hyperactivity_p, schedule_enrol, ssp_move, iqwechrawscores_vp_t, sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca913_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ca913_row1_col0\" class=\"data row1 col0\" >W2-W3</td>\n",
       "      <td id=\"T_ca913_row1_col1\" class=\"data row1 col1\" >13</td>\n",
       "      <td id=\"T_ca913_row1_col2\" class=\"data row1 col2\" >ssp_underresp, css_total, ageyrs, ssp_audfilt, ssp_lowenergy, ssp_tactile, rbs_total, site, ssp_total, ssp_move, ssp_taste, sex, absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca913_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ca913_row2_col0\" class=\"data row2 col0\" >W1-W3</td>\n",
       "      <td id=\"T_ca913_row2_col1\" class=\"data row2 col1\" >13</td>\n",
       "      <td id=\"T_ca913_row2_col2\" class=\"data row2 col2\" >ssp_underresp, css_total, ageyrs, ssp_audfilt, ssp_lowenergy, ssp_tactile, rbs_total, site, diagnosis, ssp_total, ssp_move, ssp_taste, sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca913_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ca913_row3_col0\" class=\"data row3 col0\" >W1-W2-W3</td>\n",
       "      <td id=\"T_ca913_row3_col1\" class=\"data row3 col1\" >12</td>\n",
       "      <td id=\"T_ca913_row3_col2\" class=\"data row3 col2\" >ssp_underresp, css_total, ageyrs, ssp_audfilt, ssp_lowenergy, ssp_tactile, rbs_total, site, ssp_total, ssp_move, ssp_taste, sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca913_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ca913_row4_col0\" class=\"data row4 col0\" >Unique W1</td>\n",
       "      <td id=\"T_ca913_row4_col1\" class=\"data row4 col1\" >50</td>\n",
       "      <td id=\"T_ca913_row4_col2\" class=\"data row4 col2\" >csbq_total_score, handedness, beck_dep_adultd_parent, beck_dep_youthcd, sa_css_all, aq_child_total, aq_adol_total, asbq_total_adult_parent, dawba_ext, nat_speaker, schedule_adj, group, fsiq, beck_anx_adultd_parent, aq_adult_total, piq, adhd_cat_parent, beck_dep_youthb_self_tscore, adi_rrb_total, asd_thresh, css_total_all, dawba_adhd, dawba_int, adi_communication_total, dawba_anx, ethnicity, adhd_inattentiv_self, beck_dep_adulta_self, asbq_total_adult_self, beck_anx_youthb_self_tscore, adi_social_total, css_total_imputed, beck_anx_youthb_self, viq, education_moth, adhd_hyperimpul_self, sa_css_imputed, beck_anx_youthcd_parent_t, rrb_css_all, rrb_css_imputed, dawba_behavdis, beck_anx_youthcd_parent, adhd_cat_combined, handedness_score, education_fath, beck_anx_adulta_self, adhd_cat_self, dawba_dep, beck_dep_youthb, beck_dep_youthcd_parent_t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca913_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ca913_row5_col0\" class=\"data row5 col0\" >Unique W2</td>\n",
       "      <td id=\"T_ca913_row5_col1\" class=\"data row5 col1\" >10</td>\n",
       "      <td id=\"T_ca913_row5_col2\" class=\"data row5 col2\" >cri_prorated, adhd_prorated, seq_hyperep, cri_ris, seq_hyposirs, cri_mbc, seq_total, drugclass_4, cri_total, drugclass_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca913_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ca913_row6_col0\" class=\"data row6 col0\" >Unique W3</td>\n",
       "      <td id=\"T_ca913_row6_col1\" class=\"data row6 col1\" >31</td>\n",
       "      <td id=\"T_ca913_row6_col2\" class=\"data row6 col2\" >ssp_visualaudisense, ssp_move_prorated, rbs_sterotyped, ssp_lowenergy_prorated, srs_tscore_rrb, rbs_sameness, ssp_total_prorated, ssp_visualaudisense_prorated, gender, srs_rawscore_total_self, rbs_compulsivity, srs_rawscore_total, rbs_selfinjury, srs_rawscore_sci_self, ssp_audfilt_prorated, srs_tscore_total_self, ssp_tactile_prorated, srs_tscore_rrb_self, srs_rawscore_rrb_self, ssp_underresp_prorated, ados_module, rbs_rb, rbs_ritual, ssp_taste_prorated, srs_rawscore_sci, srs_tscore_total, css_rrb, srs_rawscore_rrb, css_sa, srs_tscore_sci, srs_tscore_sci_self</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd6d2a9deb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean variable names by removing prefixes (t1_, t2_, t3_) for comparison\n",
    "variables_cleaned = {\n",
    "    wave: {var.split('_', 1)[1] for var in variables[wave] if '_' in var}\n",
    "    for wave in variables\n",
    "}\n",
    "\n",
    "# Find common variables between pairs of waves\n",
    "common_variables12 = variables_cleaned[\"wave1\"] & variables_cleaned[\"wave2\"]\n",
    "common_variables23 = variables_cleaned[\"wave2\"] & variables_cleaned[\"wave3\"]\n",
    "common_variables13 = variables_cleaned[\"wave1\"] & variables_cleaned[\"wave3\"]\n",
    "\n",
    "# Find variables common across all three waves\n",
    "common_variables123 = variables_cleaned[\"wave1\"] & variables_cleaned[\"wave2\"] & variables_cleaned[\"wave3\"]\n",
    "\n",
    "# Find unique variables in each wave\n",
    "unique_variables1 = variables_cleaned[\"wave1\"] - (variables_cleaned[\"wave2\"] | variables_cleaned[\"wave3\"])\n",
    "unique_variables2 = variables_cleaned[\"wave2\"] - (variables_cleaned[\"wave1\"] | variables_cleaned[\"wave3\"])\n",
    "unique_variables3 = variables_cleaned[\"wave3\"] - (variables_cleaned[\"wave1\"] | variables_cleaned[\"wave2\"])\n",
    "\n",
    "# Store results in a structured DataFrame for better visualization\n",
    "variable_summary = pd.DataFrame({\n",
    "    \"Comparison\": [\"W1-W2\", \"W2-W3\", \"W1-W3\", \"W1-W2-W3\", \"Unique W1\", \"Unique W2\", \"Unique W3\"],\n",
    "    \"Variable Count\": [\n",
    "        len(common_variables12), len(common_variables23), len(common_variables13),\n",
    "        len(common_variables123), len(unique_variables1), len(unique_variables2), len(unique_variables3)\n",
    "    ],\n",
    "    \"Variables\": [\n",
    "        \", \".join(common_variables12), \", \".join(common_variables23), \", \".join(common_variables13),\n",
    "        \", \".join(common_variables123), \", \".join(unique_variables1), \", \".join(unique_variables2),\n",
    "        \", \".join(unique_variables3)\n",
    "    ]})\n",
    "\n",
    "# Display information\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "styled_df = variable_summary.style.set_table_styles([{\"selector\": \"td\", \"props\": [(\"text-align\", \"left\")]}])\n",
    "display(styled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
